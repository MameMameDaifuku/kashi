{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from janome.tokenizer import Tokenizer\n",
    "from gensim.models import word2vec\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://www.uta-net.com\"\n",
    "target_url = 'https://www.uta-net.com/search/?Aselect=1&Bselect=4&Keyword=%E4%B8%AD%E6%A3%AE%E6%98%8E%E8%8F%9C&sort=4'\n",
    "music_num = 200\n",
    "\n",
    "r = requests.get(target_url)\n",
    "\n",
    "soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "url_list = []\n",
    "#曲一覧から各曲のURLを取り出してリストに入れる\n",
    "for i in range(music_num):\n",
    "   href = soup.find_all(\"td\", attrs={\"class\": \"side td1\"})[i].contents[0].get(\"href\")\n",
    "   url_list.append(href)         \n",
    "\n",
    "kashi = \"\"\n",
    "#曲ごとにRequestを送り歌詞を抽出する\n",
    "for i in range(music_num):\n",
    "   target_url = base_url + url_list[i]\n",
    "   r = requests.get(target_url)\n",
    "   soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "   for string in soup.find_all(\"div\", attrs={\"id\": \"kashi_area\"})[0].strings:\n",
    "       kashi += string\n",
    "\n",
    "with open('./kashi_txt/akina_kashi_200', mode = 'w', encoding = 'utf-8') as fw:\n",
    "   fw.write(kashi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# 英数字の削除\n",
    "kashi = re.sub(\"[a-xA-Z0-9_]\",\"\",kashi)\n",
    "# 記号の削除\n",
    "kashi = re.sub(\"[!-/:-@[-`{-~]\",\"\",kashi)\n",
    "# 空白・改行の削除\n",
    "kashi = re.sub(u'\\n\\n', '\\n', kashi)\n",
    "kashi = re.sub(u'\\r', '', kashi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    t = Tokenizer()\n",
    "    tokens = t.tokenize(text)\n",
    "    word = []\n",
    "    stop_word = create_stop_word()\n",
    "    for token in tokens:\n",
    "        part_of_speech = token.part_of_speech.split(\",\")[0]\n",
    "        if part_of_speech == \"名詞\":\n",
    "            if not token.surface in stop_word:\n",
    "                word.append(token.surface)        \n",
    "        if part_of_speech == \"動詞\":\n",
    "            if not token.base_form in stop_word:\n",
    "                word.append(token.base_form)\n",
    "        if part_of_speech == \"形容詞\":\n",
    "            if not token.base_form in stop_word:\n",
    "                word.append(token.base_form)        \n",
    "        if part_of_speech == \"形容動詞\":        \n",
    "            if not token.base_form in stop_word:\n",
    "                word.append(token.base_form)\n",
    "\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stop_word():\n",
    "    target_url = 'http://svn.sourceforge.jp/svnroot/slothlib/CSharp/Version1/SlothLib/NLP/Filter/StopWord/word/Japanese.txt'\n",
    "    r =requests.get(target_url)\n",
    "    soup=BeautifulSoup(r.text, \"html.parser\")\n",
    "    stop_word=str(soup).split()\n",
    "    return stop_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ゲーム', 0.9926275610923767), ('合う', 0.9812482595443726), ('ドラマ', 0.979516863822937), ('つくる', 0.9782220721244812), ('辿る', 0.973213255405426), ('今度', 0.972602128982544), ('なくす', 0.9723961353302002), ('時代', 0.9709115624427795), ('こわれる', 0.9708400368690491), ('ふれる', 0.9702985286712646)]\n"
     ]
    }
   ],
   "source": [
    "sentence = [tokenize(kashi)]\n",
    "model = word2vec.Word2Vec(sentence, size=100, min_count=4, window=4, iter=50)\n",
    "print(model.wv.most_similar(positive=[u\"人生\"], topn=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
